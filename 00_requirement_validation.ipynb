{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b0c392a-7c77-4cc6-a013-f326e9688969",
   "metadata": {},
   "source": [
    "# 0. Installation Validation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2348016c-4884-4936-8c4e-590d5750c781",
   "metadata": {},
   "source": [
    "Welcome to Jupyter. If this is the first time you use Jupyter, feel free to [check this tutorial](https://www.youtube.com/watch?v=2WL-XTl2QYI&t=413s) to learn how to move around the interface. (Note: Some menus and options may be different given that we have a different version)\n",
    "\n",
    "Once you are familiar with things follow the steps bellow to "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1120667-1351-47fb-917f-0aaeaa0a0f48",
   "metadata": {},
   "source": [
    "**1. Python binary**\n",
    "\n",
    "Run the following cell. The output should be the python binary in the virtual environment you created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04b3f17-273e-4479-b3dd-23aeeb4522e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0846140-9430-4739-b773-68b6e9355238",
   "metadata": {},
   "source": [
    "**2. Llama models**\n",
    "The following cell should list all the models you downloaded through ollama. You should see something similar to this: "
   ]
  },
  {
   "cell_type": "raw",
   "id": "9ecbb087-a7ef-4a02-9406-3101dffa603b",
   "metadata": {},
   "source": [
    "NAME                           ID              SIZE      MODIFIED     \n",
    "llama3.2:latest                a80c4f17acd5    2.0 GB    9 days ago      \n",
    "llama3.1:latest                62757c860e01    4.7 GB    9 days ago   \n",
    "llama3:latest                  365c0bd3c000    4.7 GB    9 days ago  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f56f11-292a-457e-8089-95aea4961cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ollama list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87b91af-1564-4535-955a-ac5bba93d100",
   "metadata": {},
   "source": [
    "**3. Libraries Check**\n",
    "\n",
    "Running the following cell should print information about Game of Thrones. \n",
    "\n",
    "If you see the following error:\n",
    "```\n",
    "ResponseError: llama runner process has terminated: signal: killed\n",
    "```\n",
    "Ensure ollama is allowed by Santa, and that Santa rules are synced up to your laptop. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb35a0a-7c0a-42a2-b8e4-019c7dcce815",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm = ChatOllama(model=\"llama3.1\", temperature=1)\n",
    "response = llm.invoke(\"who wrote A Song of Ice and Fire?\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e45c498-29ef-469e-82e4-2544c0e5cb32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
